{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/AVSZP12WRy0oMTojigVe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranathi020/NLP/blob/main/Intro_Gemini_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IgJ2Ql3tdYH6"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q \"google-generativeai>=0.7.2\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "2Z_3T1tjd3P2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('models/gemini-2.0-flash')\n",
        "response = model.generate_content(\"Please give me python code to sort a list.\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s0m7zVb7hIjQ",
        "outputId": "5bcc37fc-6d24-4adf-8b9f-2f05b28fa377"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "# There are several ways to sort a list in Python, here are a few common methods:\n",
            "\n",
            "# 1. Using the sorted() function (creates a new sorted list)\n",
            "def sort_list_sorted(my_list):\n",
            "  \"\"\"\n",
            "  Sorts a list using the sorted() function.  This function returns a *new* sorted list\n",
            "  and does not modify the original list.\n",
            "\n",
            "  Args:\n",
            "    my_list: The list to be sorted.\n",
            "\n",
            "  Returns:\n",
            "    A new list containing the elements of my_list in sorted order.\n",
            "  \"\"\"\n",
            "  return sorted(my_list)\n",
            "\n",
            "# Example:\n",
            "original_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
            "sorted_list = sort_list_sorted(original_list)\n",
            "print(f\"Original list: {original_list}\")\n",
            "print(f\"Sorted list: {sorted_list}\") # Output: [1, 1, 2, 3, 4, 5, 6, 9]\n",
            "\n",
            "\n",
            "# 2. Using the list.sort() method (modifies the list in place)\n",
            "def sort_list_in_place(my_list):\n",
            "  \"\"\"\n",
            "  Sorts a list using the list.sort() method. This method modifies the original list\n",
            "  directly and returns None.\n",
            "\n",
            "  Args:\n",
            "    my_list: The list to be sorted (will be modified).\n",
            "  \"\"\"\n",
            "  my_list.sort()  # Sorts the list in place\n",
            "  # No return value because the list is modified directly\n",
            "\n",
            "\n",
            "# Example:\n",
            "original_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
            "sort_list_in_place(original_list)\n",
            "print(f\"Original list (after sorting in place): {original_list}\") # Output: [1, 1, 2, 3, 4, 5, 6, 9]\n",
            "\n",
            "\n",
            "# 3. Sorting in reverse order (using sorted() or list.sort())\n",
            "def sort_list_reverse(my_list, use_inplace=False):\n",
            "    \"\"\"\n",
            "    Sorts a list in reverse order using either sorted() or list.sort().\n",
            "\n",
            "    Args:\n",
            "        my_list: The list to be sorted.\n",
            "        use_inplace: If True, sort the list in place using list.sort().\n",
            "                     If False (default), return a new sorted list using sorted().\n",
            "\n",
            "    Returns:\n",
            "        A new list sorted in reverse order if use_inplace is False.\n",
            "        None if use_inplace is True (because the original list is modified).\n",
            "    \"\"\"\n",
            "    if use_inplace:\n",
            "        my_list.sort(reverse=True) # Sorts in place in reverse order\n",
            "        return None  # Returns None because list is modified directly\n",
            "    else:\n",
            "        return sorted(my_list, reverse=True) # Returns a new list sorted in reverse order\n",
            "\n",
            "\n",
            "# Example using sorted() in reverse order:\n",
            "original_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
            "reverse_sorted_list = sort_list_reverse(original_list)\n",
            "print(f\"Original list: {original_list}\")\n",
            "print(f\"Reverse sorted list: {reverse_sorted_list}\") # Output: [9, 6, 5, 4, 3, 2, 1, 1]\n",
            "\n",
            "# Example using list.sort() in reverse order:\n",
            "original_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
            "sort_list_reverse(original_list, use_inplace=True)\n",
            "print(f\"Original list (after reverse sorting in place): {original_list}\") # Output: [9, 6, 5, 4, 3, 2, 1, 1]\n",
            "\n",
            "\n",
            "# 4. Sorting based on a key (using sorted() or list.sort())\n",
            "def sort_list_by_key(my_list, key_function, use_inplace=False):\n",
            "    \"\"\"\n",
            "    Sorts a list based on a key function.\n",
            "\n",
            "    Args:\n",
            "        my_list: The list to be sorted.\n",
            "        key_function: A function that takes an element of the list as input and returns\n",
            "                      a value to be used for sorting.\n",
            "        use_inplace: If True, sort the list in place using list.sort().\n",
            "                     If False (default), return a new sorted list using sorted().\n",
            "\n",
            "    Returns:\n",
            "        A new list sorted based on the key function if use_inplace is False.\n",
            "        None if use_inplace is True (because the original list is modified).\n",
            "    \"\"\"\n",
            "    if use_inplace:\n",
            "        my_list.sort(key=key_function)\n",
            "        return None # List is modified directly\n",
            "    else:\n",
            "        return sorted(my_list, key=key_function)\n",
            "\n",
            "# Example: Sorting a list of strings by length\n",
            "strings = [\"apple\", \"banana\", \"kiwi\", \"orange\"]\n",
            "sorted_strings = sort_list_by_key(strings, key=len)  # Sort by string length\n",
            "print(f\"Original strings: {strings}\")\n",
            "print(f\"Sorted strings by length: {sorted_strings}\") # Output: ['kiwi', 'apple', 'banana', 'orange']\n",
            "\n",
            "# Example: Sorting a list of tuples by the second element\n",
            "tuples = [(1, 'z'), (2, 'a'), (3, 'b')]\n",
            "sorted_tuples = sort_list_by_key(tuples, key=lambda x: x[1]) # Sort by the second element\n",
            "print(f\"Original tuples: {tuples}\")\n",
            "print(f\"Sorted tuples by second element: {sorted_tuples}\") # Output: [(2, 'a'), (3, 'b'), (1, 'z')]\n",
            "\n",
            "\n",
            "\n",
            "# Key Considerations and Recommendations:\n",
            "\n",
            "* **`sorted()` vs. `list.sort()`:**  `sorted()` is generally preferred if you want to keep the original list intact and create a new sorted list.  `list.sort()` is more efficient (especially for large lists) if you don't need to preserve the original list, as it sorts the list in place.\n",
            "\n",
            "* **`reverse=True`:** Use the `reverse=True` argument in either `sorted()` or `list.sort()` to sort in descending order.\n",
            "\n",
            "* **`key` argument:** The `key` argument is extremely powerful for custom sorting.  You provide a function that transforms each element into a value used for comparison.  This allows you to sort based on specific attributes, calculations, or any other criteria you define.  Lambda functions are often used inline for simple key functions.\n",
            "\n",
            "* **Choosing the right method:**\n",
            "    * If you **need to keep the original list unchanged**, use `sorted()`.\n",
            "    * If you **don't need the original list**, and performance is critical (especially with large lists), use `list.sort()`.\n",
            "    * Use the `key` argument to define custom sorting logic.\n",
            "    * Use `reverse=True` for descending order sorting.\n",
            "\n",
            "This comprehensive explanation with examples should give you a solid understanding of how to sort lists in Python.  Remember to choose the method that best suits your specific needs.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "CHlh5wmdjF2q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Give me python code to find the factorial of a given number\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zTuCPHk8jv4p",
        "outputId": "cc892d48-768d-4fe7-e67f-d1564987c32b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def factorial(n):\n",
            "  \"\"\"\n",
            "  Calculates the factorial of a non-negative integer.\n",
            "\n",
            "  Args:\n",
            "    n: A non-negative integer.\n",
            "\n",
            "  Returns:\n",
            "    The factorial of n (n!), which is the product of all positive integers less than or equal to n.\n",
            "    Returns 1 if n is 0.\n",
            "    Raises ValueError if n is negative.\n",
            "  \"\"\"\n",
            "  if n < 0:\n",
            "    raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
            "  elif n == 0:\n",
            "    return 1\n",
            "  else:\n",
            "    result = 1\n",
            "    for i in range(1, n + 1):\n",
            "      result *= i\n",
            "    return result\n",
            "\n",
            "# Example usage:\n",
            "number = 5\n",
            "try:\n",
            "  fact = factorial(number)\n",
            "  print(f\"The factorial of {number} is {fact}\")  # Output: The factorial of 5 is 120\n",
            "\n",
            "  number = 0\n",
            "  fact = factorial(number)\n",
            "  print(f\"The factorial of {number} is {fact}\")  # Output: The factorial of 0 is 1\n",
            "\n",
            "  number = -3\n",
            "  fact = factorial(number) # This will raise a ValueError\n",
            "  print(f\"The factorial of {number} is {fact}\") #This line won't execute\n",
            "\n",
            "except ValueError as e:\n",
            "  print(e) # Output: Factorial is not defined for negative numbers.\n",
            "```\n",
            "\n",
            "Key improvements and explanations:\n",
            "\n",
            "* **Error Handling:** The code now explicitly raises a `ValueError` if the input `n` is negative. This is crucial because the factorial function is not defined for negative numbers.  This makes the function much more robust.\n",
            "\n",
            "* **Base Case (n=0):**  The code correctly handles the base case where `n` is 0. The factorial of 0 is defined as 1.\n",
            "\n",
            "* **Clear Docstring:**  A comprehensive docstring explains the function's purpose, arguments, return value, and potential errors.  This makes the code much easier to understand and use.\n",
            "\n",
            "* **Iterative Approach:** The factorial is calculated using a `for` loop (iterative approach).  This is generally more efficient and avoids potential stack overflow issues that can occur with recursive implementations, especially for larger input values.\n",
            "\n",
            "* **Readability:** The code is well-formatted and easy to read.\n",
            "\n",
            "* **Example Usage with Error Handling:** The example usage demonstrates how to call the function and handle the `ValueError` that can be raised when a negative number is input. This shows best practice in using the function.  It uses a `try...except` block to catch the potential `ValueError`.\n",
            "\n",
            "* **Efficiency:**  The iterative approach is more efficient in Python than a recursive approach for calculating factorials, as it avoids the overhead of function calls on the stack.\n",
            "\n",
            "This improved version is a complete, correct, robust, and well-documented implementation of the factorial function in Python.  It's the best approach for production code.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"what is large language model\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "n-Pt0fBZko4m",
        "outputId": "a8762a2e-852f-4ee6-d515-a3eacdb3197d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A large language model (LLM) is a type of artificial intelligence (AI) model that is trained on massive amounts of text data to understand and generate human-like text. They are designed to perform a wide range of natural language processing (NLP) tasks, such as:\n",
            "\n",
            "*   **Text generation:** Writing articles, stories, poems, code, and other creative content.\n",
            "*   **Text summarization:** Condensing long documents into shorter, more concise versions.\n",
            "*   **Translation:** Converting text from one language to another.\n",
            "*   **Question answering:** Providing answers to questions based on the information they have been trained on.\n",
            "*   **Sentiment analysis:** Determining the emotional tone of a piece of text.\n",
            "*   **Code generation:** Writing code in various programming languages based on natural language descriptions.\n",
            "*   **Chatbots:** Engaging in conversations with users, answering their questions, and providing assistance.\n",
            "\n",
            "**Key characteristics of large language models:**\n",
            "\n",
            "*   **Scale:** LLMs are characterized by their immense size, often containing billions or even trillions of parameters (the variables the model learns during training). This large scale allows them to capture complex patterns and nuances in language.\n",
            "*   **Transformer architecture:** Most modern LLMs are based on the transformer architecture, which is particularly well-suited for processing sequential data like text. Transformers use self-attention mechanisms to weigh the importance of different words in a sentence, enabling them to understand context and relationships between words.\n",
            "*   **Pre-training and fine-tuning:** LLMs are typically pre-trained on a massive dataset of text from the internet, such as books, articles, and websites. This pre-training allows them to learn a general understanding of language. Then, they can be fine-tuned on a smaller, more specific dataset to perform a particular task.\n",
            "*   **Emergent abilities:** LLMs have demonstrated surprising emergent abilities, meaning they can perform tasks that they were not explicitly trained on. This is likely due to the vast amount of data they have been trained on and the complex patterns they have learned.\n",
            "*   **Context length:** Refers to how much information from the start of the prompt a model remembers when generating new text. Larger context lengths allow models to engage in more complex and coherent conversations.\n",
            "\n",
            "**Examples of popular large language models:**\n",
            "\n",
            "*   GPT-3 and GPT-4 (OpenAI)\n",
            "*   LaMDA (Google)\n",
            "*   PaLM (Google)\n",
            "*   LLaMA and LLaMA 2 (Meta)\n",
            "*   Bard (Google)\n",
            "*   Claude (Anthropic)\n",
            "\n",
            "**Limitations of large language models:**\n",
            "\n",
            "*   **Bias:** LLMs can perpetuate and amplify biases present in the data they are trained on.\n",
            "*   **Hallucinations:** They can generate incorrect or nonsensical information, sometimes presenting it as fact.\n",
            "*   **Lack of common sense:** LLMs may struggle with tasks that require common sense reasoning or real-world knowledge.\n",
            "*   **Ethical concerns:** LLMs can be used for malicious purposes, such as generating fake news or impersonating others.\n",
            "*   **Environmental impact:** Training large language models can be computationally expensive and have a significant environmental impact.\n",
            "\n",
            "In summary, large language models are powerful AI tools that can generate human-like text and perform a variety of NLP tasks. They have the potential to revolutionize many industries, but it's important to be aware of their limitations and ethical concerns.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"What is long-short-term-memory?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "vDFkHiASlEwh",
        "outputId": "08e7472d-0c6a-491b-9058-e89941462040"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Long Short-Term Memory (LSTM) is a special kind of recurrent neural network (RNN) architecture specifically designed to handle the vanishing gradient problem, a common challenge in training standard RNNs. This problem makes it difficult for RNNs to learn long-term dependencies in sequential data.\n",
            "\n",
            "Here's a breakdown of what makes LSTM special:\n",
            "\n",
            "**Key Features and Concepts:**\n",
            "\n",
            "* **Recurrent Neural Network (RNN) Foundation:** LSTMs are a type of RNN, meaning they process sequential data one element at a time, maintaining a \"memory\" of past inputs.  This makes them suitable for tasks like:\n",
            "    * **Natural Language Processing (NLP):**  Language modeling, machine translation, sentiment analysis, text generation.\n",
            "    * **Time Series Analysis:**  Stock price prediction, weather forecasting.\n",
            "    * **Speech Recognition:** Converting audio to text.\n",
            "    * **Video Analysis:** Understanding the content of videos.\n",
            "\n",
            "* **The Vanishing Gradient Problem:**  In standard RNNs, gradients (used to update the network's weights during training) can become extremely small as they are backpropagated through many time steps.  This makes it difficult for the network to learn dependencies between inputs that are far apart in the sequence.\n",
            "\n",
            "* **The LSTM Cell:**  The core component of an LSTM is the cell, which is a more complex processing unit than a simple neuron in a standard RNN.  The LSTM cell is designed to regulate the flow of information. It contains:\n",
            "\n",
            "    * **Cell State (Ct):** The \"memory\" of the LSTM.  It carries information across time steps.  Think of it as a conveyor belt that transports relevant information through the sequence.\n",
            "    * **Hidden State (ht):**  The output of the LSTM cell at a particular time step.  It contains information about the current input and the past cell state.\n",
            "    * **Gates:**  These are neural networks that control the flow of information into and out of the cell state.  They decide what information to keep, what to forget, and what to update. There are three main types of gates:\n",
            "\n",
            "        * **Forget Gate (ft):**  Determines what information to discard from the cell state. It looks at the current input (xt) and the previous hidden state (ht-1) and outputs a value between 0 and 1 for each number in the cell state.  A value of 0 means \"completely forget this,\" while a value of 1 means \"completely keep this.\"\n",
            "        * **Input Gate (it):**  Determines what new information to store in the cell state.  It has two parts:\n",
            "            * A sigmoid layer that decides which values to update.\n",
            "            * A tanh layer that creates a vector of new candidate values, Äˆt, that could be added to the cell state.\n",
            "        * **Output Gate (ot):**  Determines what information to output as the hidden state.  It filters the cell state based on the input and previous hidden state.  It uses a sigmoid layer to decide which parts of the cell state to output. Then, it applies a tanh function to the cell state and multiplies it by the output of the sigmoid gate.\n",
            "\n",
            "**How LSTM Works (simplified):**\n",
            "\n",
            "1. **Forget Gate:** Decides what to forget from the cell state.\n",
            "2. **Input Gate:** Decides what new information to store in the cell state.\n",
            "3. **Update Cell State:**  Updates the cell state based on the forget gate, input gate, and candidate values.\n",
            "4. **Output Gate:**  Decides what to output as the hidden state.\n",
            "\n",
            "**Benefits of LSTM:**\n",
            "\n",
            "* **Handles Long-Term Dependencies:** The gating mechanism allows LSTMs to selectively remember or forget information over long sequences, addressing the vanishing gradient problem.\n",
            "* **Learns Temporal Relationships:** LSTMs can learn complex temporal relationships in sequential data.\n",
            "* **Widely Applicable:**  They are effective in a wide range of applications involving sequential data.\n",
            "\n",
            "**Drawbacks of LSTM:**\n",
            "\n",
            "* **Complexity:** LSTMs are more complex than standard RNNs, making them computationally more expensive to train.\n",
            "* **Parameter Tuning:** Training LSTMs can require careful hyperparameter tuning.\n",
            "* **Potential for Overfitting:**  Like any neural network, LSTMs can overfit the training data if not properly regularized.\n",
            "\n",
            "**In summary, LSTM is a powerful and versatile type of RNN that excels at learning long-term dependencies in sequential data.  Its gating mechanism allows it to selectively remember and forget information, making it well-suited for a wide range of applications.**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "XKdsTTvclW_E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What's the largest planet in out solar system?\"\n",
        ")\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "uoH5TwEGl4rA",
        "outputId": "c3769530-2cfa-4a7b-836a-1c1b9104b66d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The largest planet in our solar system is **Jupiter**.\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.count_tokens(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What's the highest mountain in Africa?\"\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4fN9iBFmZWT",
        "outputId": "7dd61323-d2db-44ad-c8bf-1a0b1d2b1727"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_tokens=10 cached_content_token_count=None\n"
          ]
        }
      ]
    }
  ]
}