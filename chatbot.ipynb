{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSnlgZUK6tPWw89gvEhP7r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranathi020/NLP/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Sea3PQ5lwoA",
        "outputId": "3f61f379-e462-4beb-8d71-aced8b93c1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import atexit\n",
        "import shutil\n",
        "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
        "# Step 1: Load the pre-trained BlenderBot model and tokenizer\n",
        "model_name = \"facebook/blenderbot-1B-distill\"\n",
        "tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
        "model = BlenderbotForConditionalGeneration.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hT42TZvlfJr",
        "outputId": "f4ee7f41-7ff1-4c7c-e2ba-45e01ff3b94f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import atexit\n",
        "import shutil\n",
        "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
        "# Step 2: Define a function to interact with the chatbot\n",
        "def interact_with_chatbot(user_input, conversation_history):\n",
        "    # Step 2.1: Add user input to the conversation history\n",
        "    conversation_history.append(f\"User: {user_input}\")\n",
        "    # Step 2.2: Prepare the input text for the model\n",
        "    conversation_text = \" \".join(conversation_history[-5:])  # Use only the last 5 exchanges to keep context manageable\n",
        "    # Step 2.3: Generate a response using the chatbot pipeline\n",
        "    inputs = tokenizer(conversation_text, return_tensors=\"pt\", truncation=True)\n",
        "    response_ids = model.generate(**inputs, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
        "    response_text = tokenizer.decode(response_ids[0], skip_special_tokens=True)\n",
        "    # Step 2.4: Add the generated response to the conversation history\n",
        "    conversation_history.append(f\"Chatbot: {response_text}\")\n",
        "    return response_text"
      ],
      "metadata": {
        "id": "ODyiRHfLmHAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define a function to delete the model files from the cache directory\n",
        "def delete_model_files():\n",
        "    cache_dir = os.path.expanduser(\"~/.cache/huggingface/hub/models--facebook--blenderbot-1B-distill\")\n",
        "    if os.path.exists(cache_dir):\n",
        "        user_input = input(\"Do you want to delete the model files from the cache directory? (y/n): \")\n",
        "        if user_input.lower() == 'y':\n",
        "            shutil.rmtree(cache_dir)\n",
        "            print(f\"Deleted model files from cache directory: {cache_dir}\")\n",
        "        else:\n",
        "            print(\"Model files not deleted from cache directory.\")\n",
        "    else:\n",
        "        print(f\"Model files not found in cache directory: {cache_dir}\")"
      ],
      "metadata": {
        "id": "wI3zgRd7iuWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 4: Register the delete_mpdel_files function to be c alled on program exit\n",
        "atexit.register(delete_model_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "R1leFbBGn5eX",
        "outputId": "65d2c107-a7ec-4b01-9108-6cea9e8a3cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.delete_model_files()>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>delete_model_files</b><br/>def delete_model_files()</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/&lt;ipython-input-10-ea11477e165b&gt;</a>&lt;no docstring&gt;</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 5: start the conversation loop\n",
        "print(\"Welcome to the Indian Tourism Chatbot\")\n",
        "print(\"Type 'quit' to end the conversation.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mknLQ9GRpIVe",
        "outputId": "aed4f3b4-5439-4baf-9126-992b1e1d0dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Indian Tourism Chatbot\n",
            "Type 'quit' to end the conversation.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_history = []\n",
        "while True:\n",
        "    # Step 5.1: Get user input\n",
        "    user_input = input(\"User: \")\n",
        "    # Step 5.2: Check if the user wants to quit\n",
        "    if user_input.lower() == 'quit':\n",
        "        print(\"Thank you for using the Indian Tourism Chatbot. Goodbye!\")\n",
        "        break\n",
        "    # Step 5.3: Generate and print the chatbot's response\n",
        "    response = interact_with_chatbot(user_input, conversation_history)\n",
        "    print(f\"Chatbot: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23_3-m23p2pv",
        "outputId": "ce49b7e2-dd74-4c93-b1ae-a868daee076c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: hello\n",
            "Chatbot:  Hello! How are you today? I'm doing well, thank you. How about you?\n",
            "User: suggest me the best places in hyderabad\n",
            "Chatbot:  Hello! I am doing well. I am from Hydrobad, where are you from?\n",
            "User: best tourism places in hyderabad\n",
            "Chatbot:  I'm from the United States. I've never been there, but I've always wanted to go.\n",
            "User: give some list of beaches\n",
            "Chatbot:  I love the beach! I have been to many beaches in the Caribbean and the Gulf of Mexico.\n",
            "User: quit\n",
            "Thank you for using the Indian Tourism Chatbot. Goodbye!\n"
          ]
        }
      ]
    }
  ]
}